data_cfg:
  dataset_name: CASIA-B
  dataset_root: /kaggle/input/casiab # D:/biometrics/gait-reg/dataset/CASIA-B-pkl # D:/HCMUS/HK7/Biometric/Project/HSTL/datasets/CASIA-B-pkl
  dataset_partition: ./misc/partitions/CASIA-B_include_005.json # /kaggle/input/project-hstl/misc/partitions/CASIA-B_include_005.json
  num_workers: 4
  remove_no_gallery: false
  test_dataset_name: CASIA-B
  # cache: false

evaluator_cfg:
  enable_distributed: false
  enable_float16: false
  restore_ckpt_strict: true
  restore_hint: 80000
  save_name: kaggle # HSTL
  sampler:
    batch_size: 1
    sample_type: all_ordered
    type: InferenceSampler

loss_cfg:
  - loss_term_weight: 1.0
    margin: 0.2
    type: TripletLoss
    log_prefix: triplet
  - loss_term_weight: 1.0
    scale: 1
    type: CrossEntropyLoss
    log_accuracy: true
    label_smooth: false
    log_prefix: softmax

model_cfg:
  model: HSTL
  channels: [32, 64, 128]
  class_num: 74

optimizer_cfg:
  lr: 1.0e-4
  solver: Adam
  weight_decay: 5.0e-4

scheduler_cfg:
  gamma: 0.1
  milestones:
    - 70000
  scheduler: MultiStepLR

trainer_cfg:
  enable_distributed: false
  enable_float16: true
  # fix_BN: false
  log_iter: 100
  with_test: true # CHANGE: disable mid-training tests to save time for session
  optimizer_reset: false # true - continue with latest state
  scheduler_reset: false # true - continue with latest state
  restore_ckpt_strict: true
  restore_hint: 40000 # keep training with true setup from latest checkpoint
  save_iter: 5000 # 10000
  save_name: kaggle # HSTL
  sync_BN: false # true - CHANGE: no distributed training
  total_iter: 80000
  sampler:
    batch_shuffle: true
    batch_size: # [P,K] - [8,8] (from the paper) (T4 can handle with FP16)
      - 8
      - 8
    frames_num_fixed: 30
    frames_skip_num: 0
    # frames_skip_num_fixed: 0
    # sample_method: random_ordered
    sample_type: fixed_ordered
    type: TripletSampler

# # PHẦN QUAN TRỌNG BỊ THIẾU LÚC NÃY
# transform:
#   - type: BaseSilCuttingTransform
#     img_w: 64