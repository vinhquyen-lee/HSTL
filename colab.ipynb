{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSTL - Hierarchical Spatio-Temporal Representation Learning for Gait Recognition\n",
    "## Google Colab Notebook\n",
    "\n",
    "This notebook supports both training and inference phases for HSTL on Google Colab.\n",
    "\n",
    "**Datasets Supported:**\n",
    "- CASIA-B\n",
    "- OUMVLP\n",
    "- Gait3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if not already installed)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install pyyaml tensorboard opencv-python tqdm\n",
    "\n",
    "# Verify PyTorch installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory (adjust if needed)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# If you mounted Google Drive and your HSTL folder is there:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('/content/drive/MyDrive/path/to/HSTL')\n",
    "\n",
    "# Verify we're in the correct directory\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Files in current directory: {os.listdir('.')}\")\n",
    "\n",
    "# Add lib to Python path\n",
    "import sys\n",
    "lib_path = os.path.join(os.getcwd(), 'lib')\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.insert(0, lib_path)\n",
    "\n",
    "print(f\"\\nPython path includes lib: {lib_path in sys.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Selection\n",
    "\n",
    "Choose your dataset and configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= CONFIGURATION =============\n",
    "# Choose your dataset: 'CASIA-B', 'OUMVLP', or 'Gait3D'\n",
    "DATASET = 'CASIA-B'  # Change this to your dataset\n",
    "\n",
    "# Map dataset to config file\n",
    "CONFIG_MAP = {\n",
    "    'CASIA-B': './config/hstl.yaml',\n",
    "    'OUMVLP': './config/hstl_oumvlp.yaml',\n",
    "    'Gait3D': './config/hstl_gait3d.yaml'\n",
    "}\n",
    "\n",
    "CONFIG_FILE = CONFIG_MAP.get(DATASET, './config/hstl.yaml')\n",
    "\n",
    "# Phase: 'train' or 'test'\n",
    "PHASE = 'train'  # Change to 'test' for inference\n",
    "\n",
    "# Checkpoint iteration (for testing or resuming training)\n",
    "ITER = 0  # Set to checkpoint iteration number (e.g., 80000) or 0 for training from scratch\n",
    "\n",
    "# Log to file\n",
    "LOG_TO_FILE = True\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Dataset: {DATASET}\")\n",
    "print(f\"  Config file: {CONFIG_FILE}\")\n",
    "print(f\"  Phase: {PHASE}\")\n",
    "print(f\"  Checkpoint iteration: {ITER}\")\n",
    "print(f\"  Log to file: {LOG_TO_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Configuration and Verify Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load and display config\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(yaml.dump(config, default_flow_style=False))\n",
    "\n",
    "# Verify dataset path exists\n",
    "dataset_root = config['data_cfg']['dataset_root']\n",
    "print(f\"\\nDataset root: {dataset_root}\")\n",
    "print(f\"Dataset exists: {os.path.exists(dataset_root)}\")\n",
    "\n",
    "if not os.path.exists(dataset_root):\n",
    "    print(\"\\n⚠️ WARNING: Dataset path does not exist!\")\n",
    "    print(\"Please update the 'dataset_root' in your config file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Single-GPU Training/Testing Function\n",
    "\n",
    "Google Colab typically provides a single GPU, so we'll modify the DDP approach to work with single GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import os\n",
    "\n",
    "def setup_single_gpu():\n",
    "    \"\"\"Setup for single GPU training/testing\"\"\"\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    os.environ['WORLD_SIZE'] = '1'\n",
    "    os.environ['RANK'] = '0'\n",
    "    os.environ['LOCAL_RANK'] = '0'\n",
    "    \n",
    "    # Initialize process group with gloo backend (compatible with CPU or GPU)\n",
    "    # Use 'nccl' if you're sure CUDA is available and working\n",
    "    backend = 'nccl' if torch.cuda.is_available() else 'gloo'\n",
    "    dist.init_process_group(backend=backend, init_method='env://', world_size=1, rank=0)\n",
    "    \n",
    "    print(f\"Process group initialized with {backend} backend\")\n",
    "    print(f\"World size: {dist.get_world_size()}\")\n",
    "    print(f\"Rank: {dist.get_rank()}\")\n",
    "\n",
    "print(\"Single GPU setup function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Training or Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# Setup single GPU environment\n",
    "setup_single_gpu()\n",
    "\n",
    "# Prepare arguments for main.py\n",
    "sys.argv = [\n",
    "    'main.py',\n",
    "    '--local_rank', '0',\n",
    "    '--cfgs', CONFIG_FILE,\n",
    "    '--phase', PHASE,\n",
    "]\n",
    "\n",
    "if ITER != 0:\n",
    "    sys.argv.extend(['--iter', str(ITER)])\n",
    "\n",
    "if LOG_TO_FILE:\n",
    "    sys.argv.append('--log_to_file')\n",
    "\n",
    "print(f\"Running with arguments: {' '.join(sys.argv[1:])}\\n\")\n",
    "\n",
    "# Import and run main\n",
    "from modeling import models\n",
    "from utils import config_loader, get_ddp_module, init_seeds, params_count, get_msg_mgr\n",
    "import torch.nn as nn\n",
    "\n",
    "# Parse arguments\n",
    "parser = argparse.ArgumentParser(description='Main program')\n",
    "parser.add_argument('--local_rank', type=int, default=0)\n",
    "parser.add_argument('--cfgs', type=str, default='config/default.yaml')\n",
    "parser.add_argument('--phase', default='train', choices=['train', 'test'])\n",
    "parser.add_argument('--log_to_file', action='store_true')\n",
    "parser.add_argument('--iter', default=0)\n",
    "opt = parser.parse_args()\n",
    "\n",
    "# Load config\n",
    "cfgs = config_loader(opt.cfgs)\n",
    "if opt.iter != 0:\n",
    "    cfgs['evaluator_cfg']['restore_hint'] = int(opt.iter)\n",
    "    cfgs['trainer_cfg']['restore_hint'] = int(opt.iter)\n",
    "\n",
    "training = (opt.phase == 'train')\n",
    "\n",
    "# Initialization\n",
    "def initialization(cfgs, training):\n",
    "    msg_mgr = get_msg_mgr()\n",
    "    engine_cfg = cfgs['trainer_cfg'] if training else cfgs['evaluator_cfg']\n",
    "    output_path = os.path.join('output/', cfgs['data_cfg']['dataset_name'],\n",
    "                               cfgs['model_cfg']['model'], engine_cfg['save_name'])\n",
    "    if training:\n",
    "        msg_mgr.init_manager(output_path, opt.log_to_file, engine_cfg['log_iter'],\n",
    "                             engine_cfg['restore_hint'] if isinstance(engine_cfg['restore_hint'], (int)) else 0)\n",
    "    else:\n",
    "        msg_mgr.init_logger(output_path, opt.log_to_file)\n",
    "\n",
    "    msg_mgr.log_info(engine_cfg)\n",
    "\n",
    "    seed = torch.distributed.get_rank()\n",
    "    init_seeds(seed)\n",
    "\n",
    "# Run model\n",
    "def run_model(cfgs, training):\n",
    "    msg_mgr = get_msg_mgr()\n",
    "    model_cfg = cfgs['model_cfg']\n",
    "    msg_mgr.log_info(model_cfg)\n",
    "    Model = getattr(models, model_cfg['model'])\n",
    "    model = Model(cfgs, training)\n",
    "    if training and cfgs['trainer_cfg']['sync_BN']:\n",
    "        model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model = get_ddp_module(model)\n",
    "    msg_mgr.log_info(params_count(model))\n",
    "    msg_mgr.log_info(\"Model Initialization Finished!\")\n",
    "\n",
    "    if training:\n",
    "        Model.run_train(model)\n",
    "    else:\n",
    "        Model.run_test(model)\n",
    "\n",
    "# Execute\n",
    "print(\"Starting initialization...\")\n",
    "initialization(cfgs, training)\n",
    "print(\"\\nRunning model...\")\n",
    "run_model(cfgs, training)\n",
    "print(\"\\nCompleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Results and Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View output directory structure\n",
    "output_dir = f\"output/{DATASET}/HSTL/HSTL\"\n",
    "print(f\"Output directory: {output_dir}\\n\")\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    for root, dirs, files in os.walk(output_dir):\n",
    "        level = root.replace(output_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\n",
    "else:\n",
    "    print(\"Output directory not found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View latest log file\n",
    "log_dir = f\"output/{DATASET}/HSTL/HSTL/logs\"\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    log_files = sorted([f for f in os.listdir(log_dir) if f.endswith('.txt')])\n",
    "    if log_files:\n",
    "        latest_log = os.path.join(log_dir, log_files[-1])\n",
    "        print(f\"Latest log file: {latest_log}\\n\")\n",
    "        print(\"Last 50 lines:\")\n",
    "        print(\"=\" * 80)\n",
    "        with open(latest_log, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[-50:]:\n",
    "                print(line.rstrip())\n",
    "    else:\n",
    "        print(\"No log files found yet.\")\n",
    "else:\n",
    "    print(\"Log directory not found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TensorBoard Visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard in Colab\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Point to your output directory\n",
    "tensorboard_dir = f\"output/{DATASET}/HSTL/HSTL\"\n",
    "\n",
    "if os.path.exists(tensorboard_dir):\n",
    "    %tensorboard --logdir {tensorboard_dir}\n",
    "else:\n",
    "    print(\"TensorBoard directory not found. Train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quick Test with Specific Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with a specific checkpoint\n",
    "# This cell can be run independently after training\n",
    "\n",
    "PHASE = 'test'\n",
    "ITER = 80000  # Specify your checkpoint iteration\n",
    "\n",
    "print(f\"Testing with checkpoint iteration: {ITER}\")\n",
    "\n",
    "# Cleanup previous process group if exists\n",
    "if dist.is_initialized():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "# Re-setup and run\n",
    "setup_single_gpu()\n",
    "\n",
    "# Update sys.argv and run (similar to cell 5)\n",
    "sys.argv = [\n",
    "    'main.py',\n",
    "    '--local_rank', '0',\n",
    "    '--cfgs', CONFIG_FILE,\n",
    "    '--phase', PHASE,\n",
    "    '--iter', str(ITER),\n",
    "]\n",
    "\n",
    "if LOG_TO_FILE:\n",
    "    sys.argv.append('--log_to_file')\n",
    "\n",
    "# Reload and run\n",
    "import importlib\n",
    "import modeling.models\n",
    "importlib.reload(modeling.models)\n",
    "\n",
    "# Parse and execute\n",
    "parser = argparse.ArgumentParser(description='Main program')\n",
    "parser.add_argument('--local_rank', type=int, default=0)\n",
    "parser.add_argument('--cfgs', type=str, default='config/default.yaml')\n",
    "parser.add_argument('--phase', default='train', choices=['train', 'test'])\n",
    "parser.add_argument('--log_to_file', action='store_true')\n",
    "parser.add_argument('--iter', default=0)\n",
    "opt = parser.parse_args()\n",
    "\n",
    "cfgs = config_loader(opt.cfgs)\n",
    "if opt.iter != 0:\n",
    "    cfgs['evaluator_cfg']['restore_hint'] = int(opt.iter)\n",
    "    cfgs['trainer_cfg']['restore_hint'] = int(opt.iter)\n",
    "\n",
    "training = (opt.phase == 'train')\n",
    "initialization(cfgs, training)\n",
    "run_model(cfgs, training)\n",
    "print(\"\\nTesting completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup distributed process group\n",
    "if dist.is_initialized():\n",
    "    dist.destroy_process_group()\n",
    "    print(\"Process group destroyed\")\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU cache cleared\")\n",
    "\n",
    "print(\"Cleanup completed\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
