@article{Lee2020AutomaticCO,
  title   = {Automatic Colorization of Anime Style Illustrations Using a Two-Stage Generator},
  author  = {Yeongseop Lee and Seongjin Lee},
  journal = {Applied Sciences},
  year    = {2020},
  url     = {https://api.semanticscholar.org/CorpusID:230627543}
}

@misc{liu2017autopaintercartoonimagegeneration,
  title         = {Auto-painter: Cartoon Image Generation from Sketch by Using Conditional Generative Adversarial Networks},
  author        = {Yifan Liu and Zengchang Qin and Zhenbo Luo and Hua Wang},
  year          = {2017},
  eprint        = {1705.01908},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1705.01908}
}

@misc{thasarathan2020artistguidedsemiautomaticanimationcolorization,
  title         = {Artist-Guided Semiautomatic Animation Colorization},
  author        = {Harrish Thasarathan and Mehran Ebrahimi},
  year          = {2020},
  eprint        = {2006.13717},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2006.13717}
}

@misc{sangkloy2016scribblercontrollingdeepimage,
  title         = {Scribbler: Controlling Deep Image Synthesis with Sketch and Color},
  author        = {Patsorn Sangkloy and Jingwan Lu and Chen Fang and Fisher Yu and James Hays},
  year          = {2016},
  eprint        = {1612.00835},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1612.00835}
}

@misc{mirza2014conditionalgenerativeadversarialnets,
  title         = {Conditional Generative Adversarial Nets},
  author        = {Mehdi Mirza and Simon Osindero},
  year          = {2014},
  eprint        = {1411.1784},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1411.1784}
}

@misc{he2015deepresiduallearningimage,
  title         = {Deep Residual Learning for Image Recognition},
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year          = {2015},
  eprint        = {1512.03385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1512.03385}
}

@inproceedings{Ci_2018,
  series     = {MM ’18},
  title      = {User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks},
  url        = {http://dx.doi.org/10.1145/3240508.3240661},
  doi        = {10.1145/3240508.3240661},
  booktitle  = {Proceedings of the 26th ACM international conference on Multimedia},
  publisher  = {ACM},
  author     = {Ci, Yuanzheng and Ma, Xinzhu and Wang, Zhihui and Li, Haojie and Luo, Zhongxuan},
  year       = {2018},
  month      = oct,
  collection = {MM ’18}
}

@misc{gulrajani2017improvedtrainingwassersteingans,
      title={Improved Training of Wasserstein GANs}, 
      author={Ishaan Gulrajani and Faruk Ahmed and Martin Arjovsky and Vincent Dumoulin and Aaron Courville},
      year={2017},
      eprint={1704.00028},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1704.00028}, 
}

@misc{arjovsky2017wassersteingan,
      title={Wasserstein GAN}, 
      author={Martin Arjovsky and Soumith Chintala and Léon Bottou},
      year={2017},
      eprint={1701.07875},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1701.07875}, 
}

@misc{liang2024controlcolormultimodaldiffusionbased,
      title={Control Color: Multimodal Diffusion-based Interactive Image Colorization}, 
      author={Zhexin Liang and Zhaochen Li and Shangchen Zhou and Chongyi Li and Chen Change Loy},
      year={2024},
      eprint={2402.10855},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.10855}, 
}

@misc{rombach2022highresolutionimagesynthesislatent,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}

@misc{simonyan2015deepconvolutionalnetworkslargescale,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

@misc{zhang2023addingconditionalcontroltexttoimage,
      title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
      author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
      year={2023},
      eprint={2302.05543},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2302.05543}, 
}

@misc{yun2022icoloritpropagatinglocalhint,
      title={iColoriT: Towards Propagating Local Hint to the Right Region in Interactive Colorization by Leveraging Vision Transformer}, 
      author={Jooyeol Yun and Sanghyeon Lee and Minho Park and Jaegul Choo},
      year={2022},
      eprint={2207.06831},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2207.06831}, 
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{goodfellow2014generativeadversarialnetworks,
  title         = {Generative Adversarial Networks},
  author        = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  year          = {2014},
  eprint        = {1406.2661},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML},
  url           = {https://arxiv.org/abs/1406.2661}
}

@misc{liu2022decadescolorizationdecolorizationimages,
      title={Two Decades of Colorization and Decolorization for Images and Videos},
      author={Shiguang Liu},
      year={2022},
      eprint={2204.13322},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.13322},
}

@misc{ballester2022influencecolorspacesdeep,
      title={Influence of Color Spaces for Deep Learning Image Colorization},
      author={Coloma Ballester and Aurélie Bugeau and Hernan Carrillo and Michaël Clément and Rémi Giraud and Lara Raad and Patricia Vitoria},
      year={2022},
      eprint={2204.02850},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.02850},
}

@misc{ballester2022analysisdifferentlossesdeep,
      title={Analysis of Different Losses for Deep Learning Image Colorization},
      author={Coloma Ballester and Aurélie Bugeau and Hernan Carrillo and Michaël Clément and Rémi Giraud and Lara Raad and Patricia Vitoria},
      year={2022},
      eprint={2204.02980},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.02980},
}

@ARTICLE{9512069,
  author={Žeger, Ivana and Grgic, Sonja and Vuković, Josip and Šišul, Gordan},
  journal={IEEE Access},
  title={Grayscale Image Colorization Methods: Overview and Evaluation},
  year={2021},
  volume={9},
  number={},
  pages={113326-113346},
  keywords={Image color analysis;Deep learning;Gray-scale;Image quality;Indexes;Image segmentation;Automatic methods;black-and-white image;colorfulness;colorization;deep learning methods;example-based methods;grayscale image;image quality assessment;scribble-based methods;user-guided methods},
  doi={10.1109/ACCESS.2021.3104515}}

@misc{anwar2024imagecolorizationsurveydataset,
      title={Image Colorization: A Survey and Dataset},
      author={Saeed Anwar and Muhammad Tahir and Chongyi Li and Ajmal Mian and Fahad Shahbaz Khan and Abdul Wahab Muzaffar},
      year={2024},
      eprint={2008.10774},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2008.10774},
}

@article{HUANG2022105006,
title = {Deep learning for image colorization: Current and future prospects},
journal = {Engineering Applications of Artificial Intelligence},
volume = {114},
pages = {105006},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105006},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622001920},
author = {Shanshan Huang and Xin Jin and Qian Jiang and Li Liu},
keywords = {Image colorization, Deep learning, Convolutional neural network, Generative adversarial network, Transformer},
abstract = {Image colorization, as an essential problem in computer vision (CV), has attracted an increasing amount of researchers attention in recent years, especially deep learning-based image colorization techniques(DLIC). Generally, most recent image colorization methods can be regarded as knowledge-based systems because they are usually trained by big datasets. Unlike the existing reviews, this paper adopts a unique deep learning-based perspective to review the latest progress in image colorization techniques systematically and comprehensively. In this paper, a comprehensive review of recent DLIC approaches from algorithm classification to existing challenges is provided to facilitate researchers’ in-depth understanding of DLIC. In particular, we review DLIC algorithms from various perspectives, including color space, network structure, loss function, level of automation, and application fields. Furthermore, other important issues are discussed, such as publicly available benchmark datasets and performance evaluation metrics. Finally, we discuss several open issues of image colorization and outline future research directions. This survey can serve as a reference for researchers in image colorization and related fields.}
}